{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Upsampling\n",
    "## Overview\n",
    "Hello! We are excited to share this take-home assignment with you. Please read the problem\n",
    "statement below and raise questions if any. We are happy to clarify over email or a quick call.\n",
    "Please try to get back to us in a week. After your solution is ready, please share it with us and\n",
    "schedule a 1-hour meeting to discuss your solution\n",
    "\n",
    "## Prompt\n",
    "At Connectly, ML engineers focus on both modeling and infra work. This task is designed to test\n",
    "your ability to design, build, train, and ship ML models\n",
    "\n",
    "## Task\n",
    "Your task is to build a model and go through the full ML lifecycle. You’re given a problem to\n",
    "solve with an ML model. You’ll need to take the model through the full ML lifecycle from ideation\n",
    "to deploymen\n",
    "\n",
    "## ML Problem\n",
    "We have taken 1536 Dimensional OpenAI embeddings and applied a mystery affine\n",
    "transformation to 32 dimensions. Your job is to build a model that given the 32-dimension\n",
    "embeddings can upsample them back to 1536-dimensions in a way that preserves the cosine\n",
    "angles between vectors of the original 1536-dimension embeddings. The upsampled vectors\n",
    "should be of unit length. This model is approximating the inverse of the mystery transform\n",
    "(mystery transform is not perfectly invertable)\n",
    "\n",
    "We will provide:\n",
    "\n",
    "1. Training Embeddings: This contains 12130 32-dimensional unit length embeddings\n",
    "representing as a matrix of shape (12130,32). File:\n",
    "https://cdn.connectly.ai/interview_prompts/ml_embedding_upsample/projected_train_embs.npy\n",
    "\n",
    "\n",
    "\n",
    "1. Cosine Angle Similarity Matrix: This is a (12130, 12130) where the value at position ij\n",
    "corresponds to the cosine angle <embedding_i, embedding_j>. Since these are unit\n",
    "vectors they were calculated as dot<embedding_i, embedding_j>. These were\n",
    "calculated on the original 1536-Dimensional embeddings NOT the 32-Dimensional\n",
    "projected embeddings. File:\n",
    "https://cdn.connectly.ai/interview_prompts/ml_embedding_upsample/og_train_cos_theta.npy\n",
    "\n",
    "\n",
    "**We recommend starting with the simplest possible model and creating the service before\n",
    "optimizing the mode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12130, 12130)\n",
      "(12130, 32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "og = np.load('og_train_cos_theta.npy')\n",
    "print(og.shape)\n",
    "\n",
    "projected = np.load('projected_train_embs.npy')\n",
    "print(projected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n",
      "(2130, 32)\n",
      "(10000, 10000)\n",
      "(2130, 2130)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "projected_train = projected[: 10000]\n",
    "projected_test = projected[10000: ]\n",
    "\n",
    "og_train = og[:10000, :10000]\n",
    "og_test = og[10000:, 10000: ]\n",
    "\n",
    "print(projected_train.shape)\n",
    "print(projected_test.shape)\n",
    "\n",
    "print(og_train.shape)\n",
    "print(og_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "class FiveLayerNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FiveLayerNetwork, self).__init__()\n",
    "\n",
    "        # Define the layers\n",
    "        self.fc1 = nn.Linear(32, 64)  # First hidden layer\n",
    "        self.fc2 = nn.Linear(64, 128) # Second hidden layer\n",
    "        self.fc3 = nn.Linear(128, 256) # Third hidden layer\n",
    "        self.fc4 = nn.Linear(256, 512) # Fourth hidden layer\n",
    "        self.fc5 = nn.Linear(512, 1536) # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of the layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rowwise_mse(matrix1, matrix2):\n",
    "    if matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Both matrices should have the same shape.\")\n",
    "    \n",
    "    matrix2 = torch.from_numpy(matrix2).to(matrix1.device)  # Convert to the same device as matrix1\n",
    "    mse_per_row = torch.mean((matrix1 - matrix2)**2, axis=1)\n",
    "    return mse_per_row\n",
    "\n",
    "def get_unit_vector(tensor):\n",
    "    return tensor / torch.norm(tensor, dim=1, keepdim=True)\n",
    "\n",
    "def custom_loss(upsampled_vectors, original_cosine_similarity_subset):\n",
    "    upsampled_cosine_similarity_matrix = F.cosine_similarity(upsampled_vectors.unsqueeze(0), upsampled_vectors.unsqueeze(1), dim=2)\n",
    "    cosine_similarity_loss = rowwise_mse(upsampled_cosine_similarity_matrix, original_cosine_similarity_subset)\n",
    "    return cosine_similarity_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, SequentialSampler\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Create DataLoader for training data\n",
    "train_data = TensorDataset(torch.from_numpy(projected_train).float())\n",
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=False)\n",
    "model = FiveLayerNetwork()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.001135932443457768\n",
      "Loss decreased to 0.001135932443457768 from previous epoch. Saving model...\n",
      "Epoch 2, Loss: 0.0009952715964652277\n",
      "Loss decreased to 0.0009952715964652277 from previous epoch. Saving model...\n",
      "Epoch 3, Loss: 0.0005349121509581653\n",
      "Loss decreased to 0.0005349121509581653 from previous epoch. Saving model...\n",
      "Epoch 4, Loss: 0.000837039769259176\n",
      "Epoch 5, Loss: 0.0007622937694005988\n",
      "Epoch 6, Loss: 0.0008035679792940608\n",
      "Epoch 7, Loss: 0.0009542559251944317\n",
      "Epoch 8, Loss: 0.0008885732570207119\n",
      "Epoch 9, Loss: 0.0007306090493748895\n",
      "Epoch 10, Loss: 0.0005963255495179799\n"
     ]
    }
   ],
   "source": [
    "# Initialize variable to store the previous epoch's loss\n",
    "prev_epoch_loss = float('inf')  # Set to infinity initially so that any loss will be smaller\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    # Load the best model's weights if it exists\n",
    "    try:\n",
    "        model.load_state_dict(torch.load('best_model.pth'))\n",
    "    except FileNotFoundError:\n",
    "        pass  # File will not exist for the first epoch\n",
    "    \n",
    "    for i, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        input_data = batch[0]\n",
    "        upsampled_vectors = model(input_data)\n",
    "        upsampled_vectors = get_unit_vector(upsampled_vectors)\n",
    "        \n",
    "        batch_indices = torch.arange(i * len(input_data), (i + 1) * len(input_data))\n",
    "        \n",
    "        # Limit batch_indices to the actual size of og_train\n",
    "        batch_indices = torch.clamp(batch_indices, 0, len(og_train) - 1)\n",
    "\n",
    "        # Retrieve the subset of `og_train` using the batch indices\n",
    "        original_cosine_similarity_subset = og_train[batch_indices][:, batch_indices]\n",
    "        \n",
    "        row_loss = custom_loss(upsampled_vectors, original_cosine_similarity_subset)\n",
    "        loss = row_loss.mean()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")  # Fixed the typo from 'Item()' to 'item()'\n",
    "\n",
    "    # Check if this loss is smaller than the previous epoch's loss\n",
    "    if loss.item() < prev_epoch_loss:\n",
    "        prev_epoch_loss = loss.item()\n",
    "        print(f\"Loss decreased to {prev_epoch_loss} from previous epoch. Saving model...\")\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2130, 32])\n"
     ]
    }
   ],
   "source": [
    "test_data = torch.from_numpy(projected_test).float()\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 0.0026575695940725098\n"
     ]
    }
   ],
   "source": [
    "from torch import no_grad\n",
    "\n",
    "# Testing (evaluation)\n",
    "\n",
    "# Forward pass on test data\n",
    "model = FiveLayerNetwork()\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Initialize test loss to 0\n",
    "total_test_loss = 0\n",
    "\n",
    "# Number of samples in test_data\n",
    "N = len(test_data)\n",
    "\n",
    "# Size of each smaller square matrix\n",
    "m = 100  # Set this to the size you want\n",
    "\n",
    "# Calculate the number of blocks\n",
    "num_blocks = N // m\n",
    "\n",
    "with no_grad():\n",
    "    upsampled_test_vectors = model(test_data)\n",
    "    upsampled_test_vectors = get_unit_vector(upsampled_test_vectors)\n",
    "\n",
    "    # Iterate over the blocks\n",
    "    for i in range(num_blocks):\n",
    "        for j in range(num_blocks):\n",
    "            # Slice the matrices into smaller blocks\n",
    "            slice_upsampled = upsampled_test_vectors[i*m:(i+1)*m, :]\n",
    "            slice_og_test = og_test[i*m:(i+1)*m, j*m:(j+1)*m]\n",
    "\n",
    "            # Calculate loss for the current block\n",
    "            block_loss = custom_loss(slice_upsampled, slice_og_test)\n",
    "\n",
    "            # Accumulate the loss\n",
    "            total_test_loss += block_loss.mean().item()\n",
    "\n",
    "# Average the accumulated loss\n",
    "average_test_loss = total_test_loss / (num_blocks ** 2)\n",
    "\n",
    "print(f\"Average Test Loss: {average_test_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Service\n",
    "You should package the model as a service such that you can pass in 32 dimensional\n",
    "embeddings and it will return the upsampled embeddings (1536 dimensions). This service can\n",
    "be run locally - no need to deploy to a cloud provider (unless you want to).\n",
    "The service has 3 request types:\n",
    "1. Batch request: takes in a `.txt` file with 1 embedding per row and each value in the\n",
    "embedding is separated by a comma and writes the output upsampled embeddings to a\n",
    "`.txt` file. You must assume the file is too large to be read into memory.\n",
    "   * Request args:\n",
    "     * input_filepath\n",
    "     * output_filepath\n",
    "   * Response args:\n",
    "     * batch_request_id: unique identifier that can be used to check the status of\n",
    "the batch request.\n",
    "     * Example file 1 embedding per row with values separated by commas.\n",
    "```\n",
    "Q0.045, 0.34, 0.25, ..., -0.0094, 0.001\n",
    "0.0035, -0.087, 0.1, ..., 0.011, 0.34\n",
    "```\n",
    "1. Batch status: returns the status of the batch job\n",
    "    * Request args: batch_request_id\n",
    "    * Response args:\n",
    "      * status: Literal[‘COMPLETED’, ‘IN_PROGRESS’, ‘FAILED’]\n",
    "      * num_records_processed: the number of records processed\n",
    "2. Realtime request: optimize for low latency - the realtime request should be\n",
    "prioritized over long running batch requests. If a long running batch request is in\n",
    "progress then it should be paused to prioritize the realtime request.\n",
    "   * Request args: input_embedding\n",
    "   * Response args: upsampled_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
